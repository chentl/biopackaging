{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831242d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLUSTERING SENSITIVITY ANALYSIS ===\n",
    "# Validated with: Python 3.9+, numpy, pandas, scikit-learn, matplotlib\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG â€” EDIT THESE\n",
    "# -------------------------\n",
    "DATA_CSV = \"data/clustering_data_combined.parquet\"   # <-- path to your table of ~low-variance predictions\n",
    "OUTDIR   = \"cluster_sensitivity_outputs\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "# Columns used to cluster (e.g., 23 component loadings). You can include properties too if desired.\n",
    "# Example for 23-component loadings:\n",
    "FEATURE_COLS = [\n",
    "    \"LAP\",\"MMT\",\"CMC\",\"CNF\",\"SLK\",\"GEL\",\"CHS\",\"AGR\",\"ALG\",\"PUL\",\"CAR\",\"STA\",\n",
    "    \"FFA\",\"PEC\",\"ZIN\",\"GLU\",\"GLY\",\"XYL\",\"SRB\",\"PHA\",\"LAC\",\"LEV\",\"SUA\"\n",
    "]\n",
    "\n",
    "# If you prefer clustering in property space (or combined), set columns accordingly, e.g.:\n",
    "# FEATURE_COLS = [\"sigma_u_pred\",\"SED_pred\",\"Tvis_pred\"]  # example property-space clustering\n",
    "\n",
    "PRED_VAR_COL = \"Uncertainty\"  # prediction variance column\n",
    "PRED_VAR_MAX = 0.15        # keep only predictions below this variance threshold\n",
    "\n",
    "# (Optional) multi-property gates â€” set to None to skip\n",
    "PROPERTY_GATES = {\n",
    "    # \"sigma_u_pred\": (100, None),  # >=100 MPa\n",
    "    # \"Tvis_pred\":    (90,  None),  # >=90 %\n",
    "    # \"SED_pred\":     (15,  None),  # >=15 MJ/m^3 (or cm^3 if thatâ€™s your unit)\n",
    "}\n",
    "\n",
    "# Baseline DBSCAN params (these are the values you used in the paper)\n",
    "BASELINE = {\"eps\": 0.15, \"min_samples\": 20}\n",
    "\n",
    "# Grids to test for sensitivity\n",
    "EPS_GRID          = np.round(np.linspace(0.05, 0.30, 11), 3)   # 0.05 ... 0.30\n",
    "MIN_SAMPLES_GRID  = [5, 10, 15, 20, 25, 30]\n",
    "\n",
    "# Whether to standardize features (recommended)\n",
    "STANDARDIZE = True\n",
    "\n",
    "# Random seed for reproducibility (only used for visualization reductions)\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# LOAD & FILTER DATA\n",
    "# -------------------------\n",
    "def load_and_filter(csv_path: str,\n",
    "                    feature_cols: List[str],\n",
    "                    pred_var_col: str,\n",
    "                    pred_var_max: float,\n",
    "                    property_gates: Dict[str, Tuple[float,float]] = None) -> pd.DataFrame:\n",
    "    df = pd.read_parquet(csv_path).sample(frac=0.2)\n",
    "    df[pred_var_col] = df[pred_var_col]/100\n",
    "    missing = [c for c in feature_cols + [pred_var_col] if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in CSV: {missing}\")\n",
    "\n",
    "    # Filter by prediction variance\n",
    "    df = df[df[pred_var_col] <= pred_var_max].copy()\n",
    "\n",
    "    # Optional property gates\n",
    "    if property_gates:\n",
    "        for col, (lo, hi) in property_gates.items():\n",
    "            if col not in df.columns:\n",
    "                raise ValueError(f\"Gate column '{col}' not found in data.\")\n",
    "            if lo is not None:\n",
    "                df = df[df[col] >= lo]\n",
    "            if hi is not None:\n",
    "                df = df[df[col] <= hi]\n",
    "        df = df.copy()\n",
    "\n",
    "    if feature_cols:\n",
    "        X = df[feature_cols].values\n",
    "    else:\n",
    "        # if no feature list given, assume all numeric except known non-features\n",
    "        non_feature = {pred_var_col}\n",
    "        if property_gates:\n",
    "            non_feature |= set(property_gates.keys())\n",
    "        feature_cols_auto = [c for c in df.columns if (df[c].dtype != \"O\" and c not in non_feature)]\n",
    "        print(f\"[INFO] FEATURE_COLS not provided. Auto-detected numeric columns (excl. gates/variance): {feature_cols_auto}\")\n",
    "        X = df[feature_cols_auto].values\n",
    "\n",
    "    return df, X, (feature_cols if feature_cols else feature_cols_auto)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# CLUSTERING HELPERS\n",
    "# -------------------------\n",
    "def run_dbscan(X: np.ndarray, eps: float, min_samples: int) -> np.ndarray:\n",
    "    cl = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1)\n",
    "    return cl.fit_predict(X)\n",
    "\n",
    "def clustering_quality(X: np.ndarray, labels: np.ndarray) -> Dict[str, float]:\n",
    "    # Exclude noise (-1) for silhouette\n",
    "    mask = labels != -1\n",
    "    quality = {\n",
    "        \"n_points\": int(X.shape[0]),\n",
    "        \"n_noise\": int(np.sum(~mask)),\n",
    "        \"noise_frac\": float(np.mean(~mask)),\n",
    "        \"n_clusters\": int(len(set(labels)) - (1 if -1 in labels else 0)),\n",
    "        \"silhouette\": np.nan\n",
    "    }\n",
    "    # Silhouette defined only if >=2 clusters and at least 1 non-noise point per cluster\n",
    "    if np.sum(mask) > 1 and quality[\"n_clusters\"] >= 2:\n",
    "        try:\n",
    "            quality[\"silhouette\"] = float(silhouette_score(X[mask], labels[mask]))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return quality\n",
    "\n",
    "def compare_partitions(y_ref: np.ndarray, y_alt: np.ndarray) -> Dict[str, float]:\n",
    "    # Stability measures (treat noise as its own label)\n",
    "    return {\n",
    "        \"ARI_vs_baseline\": float(adjusted_rand_score(y_ref, y_alt)),\n",
    "        \"NMI_vs_baseline\": float(normalized_mutual_info_score(y_ref, y_alt))\n",
    "    }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# MAIN ANALYSIS\n",
    "# -------------------------\n",
    "def main():\n",
    "    df, X_raw, used_feats = load_and_filter(\n",
    "        DATA_CSV, FEATURE_COLS, PRED_VAR_COL, PRED_VAR_MAX, PROPERTY_GATES\n",
    "    )\n",
    "    print(f\"[INFO] Data after filtering: {df.shape[0]} rows\")\n",
    "    print(f\"[INFO] Using {len(used_feats)} feature columns: {used_feats}\")\n",
    "\n",
    "    # Standardize (recommended for distance-based clustering)\n",
    "    if STANDARDIZE:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X_raw)\n",
    "    else:\n",
    "        X = X_raw\n",
    "\n",
    "    # Baseline DBSCAN\n",
    "    base_labels = run_dbscan(X, eps=BASELINE[\"eps\"], min_samples=BASELINE[\"min_samples\"])\n",
    "    base_stats  = clustering_quality(X, base_labels)\n",
    "    base_stats.update({\"eps\": BASELINE[\"eps\"], \"min_samples\": BASELINE[\"min_samples\"], \"algorithm\": \"DBSCAN\"})\n",
    "    print(\"[BASELINE] \", base_stats)\n",
    "\n",
    "    # Grid search DBSCAN sensitivity\n",
    "    rows = []\n",
    "    for eps, ms in product(EPS_GRID, MIN_SAMPLES_GRID):\n",
    "        labels = run_dbscan(X, eps=eps, min_samples=ms)\n",
    "        stats  = clustering_quality(X, labels)\n",
    "        stab   = compare_partitions(base_labels, labels)\n",
    "        stats.update({\"eps\": float(eps), \"min_samples\": int(ms), \"algorithm\": \"DBSCAN\"})\n",
    "        stats.update(stab)\n",
    "        rows.append(stats)\n",
    "\n",
    "    sens_df = pd.DataFrame(rows).sort_values([\"eps\", \"min_samples\"]).reset_index(drop=True)\n",
    "    sens_csv = os.path.join(OUTDIR, \"dbscan_sensitivity_summary.csv\")\n",
    "    sens_df.to_csv(sens_csv, index=False)\n",
    "    print(f\"[SAVE] DBSCAN sensitivity table -> {sens_csv}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # PLOTS (simple, matplotlib, 1 chart per fig; no explicit colors)\n",
    "    # -------------------------\n",
    "\n",
    "    # 1) Heatmap-like scatter: ARI vs baseline as a function of eps & min_samples\n",
    "    fig1 = plt.figure(figsize=(7,5))\n",
    "    pivot_ari = sens_df.pivot(index=\"min_samples\", columns=\"eps\", values=\"ARI_vs_baseline\")\n",
    "    plt.imshow(pivot_ari.values, aspect=\"auto\", origin=\"lower\", extent=[\n",
    "        pivot_ari.columns.min(), pivot_ari.columns.max(), pivot_ari.index.min(), pivot_ari.index.max()\n",
    "    ])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"eps\")\n",
    "    plt.ylabel(\"min_samples\")\n",
    "    plt.title(\"DBSCAN stability (ARI vs. baseline)\")\n",
    "    plt.tight_layout()\n",
    "    fig1_path = os.path.join(OUTDIR, \"dbscan_ari_heatmap.png\")\n",
    "    plt.savefig(fig1_path, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"[SAVE] {fig1_path}\")\n",
    "\n",
    "    # 2) Line plot: noise fraction vs eps for each min_samples\n",
    "    fig2 = plt.figure(figsize=(7,5))\n",
    "    for ms in MIN_SAMPLES_GRID:\n",
    "        sub = sens_df[sens_df[\"min_samples\"]==ms]\n",
    "        plt.plot(sub[\"eps\"], sub[\"noise_frac\"], marker=\"o\", label=f\"min_samples={ms}\")\n",
    "    plt.xlabel(\"eps\")\n",
    "    plt.ylabel(\"noise fraction\")\n",
    "    plt.title(\"DBSCAN noise fraction across eps\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    fig2_path = os.path.join(OUTDIR, \"dbscan_noise_fraction.png\")\n",
    "    plt.savefig(fig2_path, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"[SAVE] {fig2_path}\")\n",
    "\n",
    "    # 3) Line plot: number of clusters vs eps\n",
    "    fig3 = plt.figure(figsize=(7,5))\n",
    "    for ms in MIN_SAMPLES_GRID:\n",
    "        sub = sens_df[sens_df[\"min_samples\"]==ms]\n",
    "        plt.plot(sub[\"eps\"], sub[\"n_clusters\"], marker=\"o\", label=f\"min_samples={ms}\")\n",
    "    plt.xlabel(\"eps\")\n",
    "    plt.ylabel(\"# clusters\")\n",
    "    plt.title(\"DBSCAN number of clusters across eps\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    fig3_path = os.path.join(OUTDIR, \"dbscan_num_clusters.png\")\n",
    "    plt.savefig(fig3_path, dpi=200)\n",
    "    plt.close()\n",
    "    print(f\"[SAVE] {fig3_path}\")\n",
    "\n",
    "    # 4) Optional: a simple 2D PCA scatter with baseline labels (quick visual sanity check)\n",
    "    try:\n",
    "        pca = PCA(n_components=2, random_state=RANDOM_STATE)\n",
    "        X2 = pca.fit_transform(X)\n",
    "        fig5 = plt.figure(figsize=(6,5))\n",
    "        # Noise first\n",
    "        noise_mask = base_labels == -1\n",
    "        plt.scatter(X2[noise_mask,0], X2[noise_mask,1], s=5, alpha=0.5, label=\"noise\")\n",
    "        # Clusters\n",
    "        for lab in sorted(set(base_labels) - {-1}):\n",
    "            m = base_labels == lab\n",
    "            plt.scatter(X2[m,0], X2[m,1], s=5, alpha=0.8, label=f\"cluster {lab}\")\n",
    "        plt.title(f\"Baseline DBSCAN (eps={BASELINE['eps']}, min_samples={BASELINE['min_samples']})\")\n",
    "        plt.xlabel(\"PC1\")\n",
    "        plt.ylabel(\"PC2\")\n",
    "        plt.legend(markerscale=3)\n",
    "        plt.tight_layout()\n",
    "        fig4_path = os.path.join(OUTDIR, \"baseline_pca_scatter.png\")\n",
    "        plt.savefig(fig4_path, dpi=200)\n",
    "        plt.close()\n",
    "        print(f\"[SAVE] {fig4_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] PCA scatter skipped: {e}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # PRINT A QUICK TEXT SUMMARY\n",
    "    # -------------------------\n",
    "    def short_stats(df, eps, ms):\n",
    "        row = df[(df[\"eps\"]==eps) & (df[\"min_samples\"]==ms)].head(1)\n",
    "        if row.empty: return None\n",
    "        r = row.iloc[0].to_dict()\n",
    "        return {\n",
    "            \"n_clusters\": r[\"n_clusters\"],\n",
    "            \"noise_frac\": r[\"noise_frac\"],\n",
    "            \"silhouette\": r[\"silhouette\"],\n",
    "            \"ARI_vs_baseline\": r[\"ARI_vs_baseline\"],\n",
    "            \"NMI_vs_baseline\": r[\"NMI_vs_baseline\"]\n",
    "        }\n",
    "\n",
    "    print(\"\\n=== QUICK CHECKPOINTS ===\")\n",
    "    for (e, m) in [(0.10, 20), (0.15, 20), (0.20, 20)]:\n",
    "        s = short_stats(sens_df, e, m)\n",
    "        if s:\n",
    "            print(f\"eps={e}, min_samples={m} -> {s}\")\n",
    "    print(\"Done.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f20446a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Data after filtering: 95597 rows\n",
      "[INFO] Using 23 feature columns: ['LAP', 'MMT', 'CMC', 'CNF', 'SLK', 'GEL', 'CHS', 'AGR', 'ALG', 'PUL', 'CAR', 'STA', 'FFA', 'PEC', 'ZIN', 'GLU', 'GLY', 'XYL', 'SRB', 'PHA', 'LAC', 'LEV', 'SUA']\n",
      "[BASELINE]  {'n_points': 95597, 'n_noise': 95549, 'noise_frac': 0.9994978921932697, 'n_clusters': 2, 'silhouette': 0.4452048075870825, 'eps': 0.15, 'min_samples': 20, 'algorithm': 'DBSCAN'}\n",
      "[SAVE] DBSCAN sensitivity table -> cluster_sensitivity_outputs/dbscan_sensitivity_summary.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 183\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    177\u001b[39m optics_param_grid = [\n\u001b[32m    178\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mmin_samples\u001b[39m\u001b[33m\"\u001b[39m: ms, \u001b[33m\"\u001b[39m\u001b[33mxi\u001b[39m\u001b[33m\"\u001b[39m: xi, \u001b[33m\"\u001b[39m\u001b[33mmin_cluster_size\u001b[39m\u001b[33m\"\u001b[39m: ms}\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ms \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m10\u001b[39m, \u001b[32m20\u001b[39m, \u001b[32m30\u001b[39m]\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m xi \u001b[38;5;129;01min\u001b[39;00m [\u001b[32m0.03\u001b[39m, \u001b[32m0.05\u001b[39m, \u001b[32m0.10\u001b[39m]\n\u001b[32m    181\u001b[39m ]\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m optics_param_grid:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     labels = \u001b[43mrun_optics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmin_samples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxi\u001b[49m\u001b[43m=\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_cluster_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmin_cluster_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m     stats  = clustering_quality(X, labels)\n\u001b[32m    185\u001b[39m     stab   = compare_partitions(base_labels, labels)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mrun_optics\u001b[39m\u001b[34m(X, min_samples, xi, min_cluster_size)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_optics\u001b[39m(X: np.ndarray, min_samples: \u001b[38;5;28mint\u001b[39m = \u001b[32m20\u001b[39m, xi: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.05\u001b[39m, min_cluster_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m20\u001b[39m) -> np.ndarray:\n\u001b[32m    107\u001b[39m     cl = OPTICS(min_samples=min_samples, xi=xi, min_cluster_size=min_cluster_size, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     labels = \u001b[43mcl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/sklearn/base.py:695\u001b[39m, in \u001b[36mClusterMixin.fit_predict\u001b[39m\u001b[34m(self, X, y, **kwargs)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    673\u001b[39m \u001b[33;03mPerform clustering on `X` and returns cluster labels.\u001b[39;00m\n\u001b[32m    674\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    691\u001b[39m \u001b[33;03m    Cluster labels.\u001b[39;00m\n\u001b[32m    692\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    693\u001b[39m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[32m    694\u001b[39m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.labels_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/sklearn/cluster/_optics.py:351\u001b[39m, in \u001b[36mOPTICS.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    343\u001b[39m         X.setdiag(X.diagonal())\n\u001b[32m    344\u001b[39m memory = check_memory(\u001b[38;5;28mself\u001b[39m.memory)\n\u001b[32m    346\u001b[39m (\n\u001b[32m    347\u001b[39m     \u001b[38;5;28mself\u001b[39m.ordering_,\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m.core_distances_,\n\u001b[32m    349\u001b[39m     \u001b[38;5;28mself\u001b[39m.reachability_,\n\u001b[32m    350\u001b[39m     \u001b[38;5;28mself\u001b[39m.predecessor_,\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m ) = \u001b[43mmemory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_optics_graph\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmin_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mleaf_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mleaf_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_params\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetric_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_eps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[38;5;66;03m# Extract clusters from the calculated orders and reachability\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cluster_method == \u001b[33m\"\u001b[39m\u001b[33mxi\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/joblib/memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/sklearn/cluster/_optics.py:648\u001b[39m, in \u001b[36mcompute_optics_graph\u001b[39m\u001b[34m(X, min_samples, max_eps, metric, p, metric_params, algorithm, leaf_size, n_jobs)\u001b[39m\n\u001b[32m    646\u001b[39m     ordering[ordering_idx] = point\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m core_distances_[point] != np.inf:\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m         \u001b[43m_set_reach_dist\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcore_distances_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcore_distances_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreachability_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreachability_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpredecessor_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpredecessor_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpoint_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnbrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnbrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetric_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m            \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmax_eps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_eps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.all(np.isinf(reachability_)):\n\u001b[32m    662\u001b[39m     warnings.warn(\n\u001b[32m    663\u001b[39m         (\n\u001b[32m    664\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mAll reachability values are inf. Set a larger\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    667\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    668\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/sklearn/cluster/_optics.py:689\u001b[39m, in \u001b[36m_set_reach_dist\u001b[39m\u001b[34m(core_distances_, reachability_, predecessor_, point_index, processed, X, nbrs, metric, metric_params, p, max_eps)\u001b[39m\n\u001b[32m    685\u001b[39m P = X[point_index : point_index + \u001b[32m1\u001b[39m]\n\u001b[32m    686\u001b[39m \u001b[38;5;66;03m# Assume that radius_neighbors is faster without distances\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# and we don't need all distances, nevertheless, this means\u001b[39;00m\n\u001b[32m    688\u001b[39m \u001b[38;5;66;03m# we may be doing some work twice.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m689\u001b[39m indices = \u001b[43mnbrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mradius_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_eps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    691\u001b[39m \u001b[38;5;66;03m# Getting indices of neighbors that have not been processed\u001b[39;00m\n\u001b[32m    692\u001b[39m unproc = np.compress(~np.take(processed, indices), indices)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/sklearn/neighbors/_base.py:1202\u001b[39m, in \u001b[36mRadiusNeighborsMixin.radius_neighbors\u001b[39m\u001b[34m(self, X, radius, return_distance, sort_results)\u001b[39m\n\u001b[32m   1194\u001b[39m use_pairwise_distances_reductions = (\n\u001b[32m   1195\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_method == \u001b[33m\"\u001b[39m\u001b[33mbrute\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1196\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m RadiusNeighbors.is_usable_for(\n\u001b[32m   1197\u001b[39m         X \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fit_X, \u001b[38;5;28mself\u001b[39m._fit_X, \u001b[38;5;28mself\u001b[39m.effective_metric_\n\u001b[32m   1198\u001b[39m     )\n\u001b[32m   1199\u001b[39m )\n\u001b[32m   1201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_pairwise_distances_reductions:\n\u001b[32m-> \u001b[39m\u001b[32m1202\u001b[39m     results = \u001b[43mRadiusNeighbors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m=\u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meffective_metric_params_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m   1214\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_method == \u001b[33m\"\u001b[39m\u001b[33mbrute\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metric == \u001b[33m\"\u001b[39m\u001b[33mprecomputed\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m issparse(X)\n\u001b[32m   1215\u001b[39m ):\n\u001b[32m   1216\u001b[39m     results = _radius_neighbors_from_graph(\n\u001b[32m   1217\u001b[39m         X, radius=radius, return_distance=return_distance\n\u001b[32m   1218\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py:425\u001b[39m, in \u001b[36mRadiusNeighbors.compute\u001b[39m\u001b[34m(cls, X, Y, radius, metric, chunk_size, metric_kwargs, strategy, return_distance, sort_results)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the results of the reduction for the given arguments.\u001b[39;00m\n\u001b[32m    340\u001b[39m \n\u001b[32m    341\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    422\u001b[39m \u001b[33;03mreturns.\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.dtype == Y.dtype == np.float64:\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRadiusNeighbors64\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mY\u001b[49m\u001b[43m=\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m=\u001b[49m\u001b[43mradius\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m X.dtype == Y.dtype == np.float32:\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m RadiusNeighbors32.compute(\n\u001b[32m    439\u001b[39m         X=X,\n\u001b[32m    440\u001b[39m         Y=Y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m         return_distance=return_distance,\n\u001b[32m    448\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32msklearn/metrics/_pairwise_distances_reduction/_radius_neighbors.pyx:91\u001b[39m, in \u001b[36msklearn.metrics._pairwise_distances_reduction._radius_neighbors.RadiusNeighbors64.compute\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msklearn/metrics/_pairwise_distances_reduction/_radius_neighbors.pyx:387\u001b[39m, in \u001b[36msklearn.metrics._pairwise_distances_reduction._radius_neighbors.EuclideanRadiusNeighbors64.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msklearn/metrics/_pairwise_distances_reduction/_base.pyx:110\u001b[39m, in \u001b[36msklearn.metrics._pairwise_distances_reduction._base._sqeuclidean_row_norms64\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/NLP/lib/python3.13/site-packages/scipy/_lib/_sparse.py:10\u001b[39m, in \u001b[36missparse\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSparseABC\u001b[39;00m(ABC):\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34missparse\u001b[39m(x):\n\u001b[32m     11\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Is `x` of a sparse array or sparse matrix type?\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m \u001b[33;03m    False\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, SparseABC)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48b864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the streamlined sensitivity analysis (OPTICS removed for speed)\n",
    "print(\"ðŸš€ Starting streamlined DBSCAN sensitivity analysis...\")\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823efa8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adced95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
