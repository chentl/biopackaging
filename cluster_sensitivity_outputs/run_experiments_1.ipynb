{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ [01] Imports and Configuration Module Loaded\n",
      "📊 Dataset Configuration (aligned with ann_model):\n",
      "   📋 Input features: 23\n",
      "   🎯 Prediction tasks: ['optical', 'tensile']\n",
      "      optical: 3 targets - ['TransVis', 'TransIR', 'TransUV']\n",
      "      tensile: 4 targets - ['TensileStress', 'TensileStrain', 'TensileModulusLog10', 'TensileToughnessMean100n90']\n",
      "🔧 Environment Information:\n",
      "   🔮 PyTorch version: 2.8.0+cpu\n",
      "   💻 Device: CPU\n",
      "   🎲 Random seed: 0\n",
      "   🚀 Parallel processing: 10 cores available\n",
      "📁 Loaded dataset shape: (342, 42)\n",
      "🧹 After removing missing targets: (342, 42)\n",
      "📈 Data retention: 100.0%\n",
      "\n",
      "📋 Dataset Summary:\n",
      "   Total samples: 342\n",
      "   Input features: 23\n",
      "   Target variables: 7\n",
      "   Missing values in targets: 0\n",
      "\n",
      "📊 Target Variable Ranges:\n",
      "\n",
      "OPTICAL Targets:\n",
      "  TransVis: [2.37, 275.10] (mean: 70.17)\n",
      "  TransIR: [3.10, 86.27] (mean: 69.21)\n",
      "  TransUV: [0.00, 100.00] (mean: 45.02)\n",
      "\n",
      "TENSILE Targets:\n",
      "  TensileStress: [0.36, 161.67] (mean: 39.95)\n",
      "  TensileStrain: [0.07, 75.03] (mean: 5.84)\n",
      "  TensileModulusLog10: [0.60, 4.34] (mean: 3.50)\n",
      "  TensileToughnessMean100n90: [0.00, 9.98] (mean: 0.86)\n",
      "\n",
      "✅ [02] Data Loading and Preparation Module Loaded\n",
      "🗂️  Dataset Processing Summary:\n",
      "   📊 Original dataset: 342 samples\n",
      "   🧹 After cleaning: 342 samples\n",
      "   📈 Data retention: 100.0%\n",
      "   🔗 Input features: 23\n",
      "   🎯 Target variables: 7\n",
      "📊 Deep Dive - Target Statistics:\n",
      "\n",
      "OPTICAL Properties:\n",
      "  TransVis: [2.367, 275.100] μ=70.169, σ=16.064\n",
      "  TransIR: [3.100, 86.267] μ=69.208, σ=11.277\n",
      "  TransUV: [0.000, 100.000] μ=45.020, σ=13.603\n",
      "\n",
      "TENSILE Properties:\n",
      "  TensileStress: [0.365, 161.667] μ=39.950, σ=32.949\n",
      "  TensileStrain: [0.070, 75.035] μ=5.838, σ=11.199\n",
      "  TensileModulusLog10: [0.596, 4.342] μ=3.501, σ=0.717\n",
      "  TensileToughnessMean100n90: [0.001, 9.981] μ=0.863, σ=1.387\n",
      "✅ Neural Network Architecture Created (aligned with ann_model/base.py)\n",
      "📏 Input dimension: 23\n",
      "🔗 Hidden output dimension: 64\n",
      "⚙️ Total parameters: 11,328\n",
      "💾 Model size: ~44.2 KB\n",
      "\n",
      "✅ [03] Neural Network Architecture Module Loaded\n",
      "🏗️ Architecture Summary (ANNModel from ann_model/base.py):\n",
      "   📏 Input features: 23\n",
      "   🔗 Output dimensions: 64\n",
      "   ⚙️ Total parameters: 11,328\n",
      "   💾 Memory footprint: ~44.2 KB\n",
      "🔧 Key Features:\n",
      "   🏗️ ModuleDict-based layers: ✅\n",
      "   🎲 Dropout support: ✅\n",
      "   🎯 Weight initialization: kaiming_uniform_\n",
      "   🔄 All PyTorch activations supported\n",
      "⚠️ smogn not available, SMOTE will use fallback method\n",
      "✅ Section 4: Data Augmentation Methods Complete\n",
      "🔧 UIP parameters (base): comp_sigma=0.01, prop_sigma=0.15\n",
      "🔧 UIP uses HYBRID noise approach:\n",
      "   • Experimental std (when available) - most realistic!\n",
      "   • Adaptive relative noise (fallback) - scales with sqrt(ratio)\n",
      "   • ratio=1: 15% fallback, ratio=10: 4.7% fallback, ratio=100: 1.5% fallback\n",
      "🔧 SMOTE-Regression: Using fallback (smogn not available)\n",
      "   • Install smogn for optimal SMOTE performance: pip install smogn\n",
      "🔧 Ratio-based functions: UIP and SMOTE ratio variants available\n",
      "✅ Section 5: Training Utilities Complete (aligned with ann_model/trainer.py)\n",
      "🔧 Hyperparameter space: 3072 total combinations\n",
      "🔧 Training function: train_model() with Adam optimizer\n",
      "🔧 Metrics: compute_mre_percent() aligned with ann_model/metrics.py\n",
      "🔧 Ensemble function: Full pipeline with error handling\n",
      "✅ [06] Model Architectures and Hyperparameter Configurations Loaded\n",
      "   (Aligned with ann_model/config.py)\n",
      "📊 Config Classes:\n",
      "   ✓ ModelConfig: Encoder + task-specific heads (grade, tensile, optical, fire)\n",
      "   ✓ FitConfig: Training hyperparameters\n",
      "📊 Architecture configurations: 3\n",
      "🔧 Hyperparameter sets per architecture: 5\n",
      "🎯 SCALED Architecture Strategy:\n",
      "   ✓ Simple (1:1):   (64, 32) - batch=32, epochs=100, dropout=0.1\n",
      "   ✓ Medium (1:10):  (128, 64, 32) - batch=64, epochs=150, dropout=0.15 + BatchNorm\n",
      "   ✓ Complex (1:100): (256, 128, 64, 32) - batch=128, epochs=200, dropout=0.2 + BatchNorm\n",
      "   ✓ More data → Larger models → Better capacity without overfitting\n",
      "✅ [07] Parallel Training Utilities Loaded\n",
      "   (Aligned with ann_model/metrics.py and ann_model/trainer.py)\n",
      "🚀 Parallel processing configured for ensemble training\n",
      "🔧 Functions: train_single_model_parallel(), train_ensemble_parallel()\n",
      "📊 Metrics: MSE, MAE, MRE (%), R² - matching ann_model/metrics.py\n",
      "✅ [08] Experiment Runners Loaded (aligned with ann_model, with data-driven scales)\n",
      "🔧 Functions: run_uip_experiment(), run_smote_experiment(), run_baseline_experiment()\n",
      "🎯 Each function runs full ensemble experiments for a specific augmentation method\n",
      "⚠️  Key Update: Targets are scaled using data-driven TARGET_Y_SCALES:\n",
      "   • Optical: Scaled by [300, 100, 100] for TransVis/TransIR/TransUV (Sigmoid activation)\n",
      "   • Tensile: Scaled by [150, 150, 3, 20] (ReLU activation)\n",
      "   • MRE and R² calculated on ORIGINAL scale for interpretability\n",
      "✅ Core sections loaded.\n"
     ]
    }
   ],
   "source": [
    "for sec in [\n",
    "    '01_imports_and_configuration',\n",
    "    '02_data_loading_and_preparation',\n",
    "    '03_neural_network_architecture',\n",
    "    '04_data_augmentation_methods',\n",
    "    '05_training_and_hyperparameter_tuning',\n",
    "    '06_model_architectures_and_configs',\n",
    "    '07_parallel_training_utilities',\n",
    "    '08_experiment_runners'\n",
    "]:\n",
    "    exec(open(f'core_sections/{sec}.py').read())\n",
    "print(\"✅ Core sections loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting UIP experiments for tensile properties...\n",
      "\n",
      "🚀 UIP EXPERIMENT: TENSILE\n",
      "============================================================\n",
      "🎯 Target properties: ['TensileStress', 'TensileStrain', 'TensileModulusLog10', 'TensileToughnessMean100n90']\n",
      "📊 Raw Data: Train=(273, 23), Test=(69, 23) (with experimental std)\n",
      "\n",
      "🔧 Testing UIP Ratio: 1:1\n",
      "----------------------------------------\n",
      "🏗️ Using simple architecture with 5 ensemble models\n",
      "📈 Augmented data: 546 samples (2.0x)\n",
      "   Hybrid noise: Experimental std (where available) + 15.0% fallback\n",
      "   Targets scaled by TARGET_Y_SCALES [150, 150, 3, 20] for ReLU activation\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=86.003%, R²=0.617\n",
      "      🤖 Model 2: MRE=88.145%, R²=0.603\n",
      "      🤖 Model 3: MRE=89.296%, R²=0.617\n",
      "      🤖 Model 4: MRE=86.285%, R²=0.627\n",
      "      🤖 Model 5: MRE=85.277%, R²=0.610\n",
      "\n",
      "✅ UIP Ensemble Results for 1:1:\n",
      "   📊 Ensemble MRE: 83.837% (original scale)\n",
      "   📊 Ensemble R²: 0.623 (vs individual mean: 0.615)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (64, 32)\n",
      "   📈 Samples: 546 (2.0x)\n",
      "\n",
      "   📉 Individual Model Losses:\n",
      "      Model 1: Train Loss=0.011106, Val Loss=0.011453\n",
      "      Model 2: Train Loss=0.011171, Val Loss=0.012355\n",
      "      Model 3: Train Loss=0.009955, Val Loss=0.011887\n",
      "      Model 4: Train Loss=0.011566, Val Loss=0.011154\n",
      "      Model 5: Train Loss=0.010123, Val Loss=0.012032\n",
      "   📉 Ensemble Average Losses:\n",
      "      Train Loss: 0.010784 ± 0.000631\n",
      "      Val Loss: 0.011776 ± 0.000425\n",
      "\n",
      "🔧 Testing UIP Ratio: 1:10\n",
      "----------------------------------------\n",
      "🏗️ Using medium architecture with 5 ensemble models\n",
      "📈 Augmented data: 3003 samples (11.0x)\n",
      "   Hybrid noise: Experimental std (where available) + 4.7% fallback\n",
      "   Targets scaled by TARGET_Y_SCALES [150, 150, 3, 20] for ReLU activation\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=85.714%, R²=0.599\n",
      "      🤖 Model 2: MRE=79.987%, R²=0.581\n",
      "      🤖 Model 3: MRE=80.473%, R²=0.569\n",
      "      🤖 Model 4: MRE=81.705%, R²=0.590\n",
      "      🤖 Model 5: MRE=85.023%, R²=0.583\n",
      "\n",
      "✅ UIP Ensemble Results for 1:10:\n",
      "   📊 Ensemble MRE: 80.145% (original scale)\n",
      "   📊 Ensemble R²: 0.595 (vs individual mean: 0.584)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (128, 64, 32)\n",
      "   📈 Samples: 3003 (11.0x)\n",
      "\n",
      "   📉 Individual Model Losses:\n",
      "      Model 1: Train Loss=0.006220, Val Loss=0.013912\n",
      "      Model 2: Train Loss=0.006544, Val Loss=0.014246\n",
      "      Model 3: Train Loss=0.006047, Val Loss=0.014364\n",
      "      Model 4: Train Loss=0.006333, Val Loss=0.013361\n",
      "      Model 5: Train Loss=0.006462, Val Loss=0.013793\n",
      "   📉 Ensemble Average Losses:\n",
      "      Train Loss: 0.006321 ± 0.000176\n",
      "      Val Loss: 0.013935 ± 0.000355\n",
      "\n",
      "🔧 Testing UIP Ratio: 1:100\n",
      "----------------------------------------\n",
      "🏗️ Using complex architecture with 5 ensemble models\n",
      "📈 Augmented data: 27573 samples (101.0x)\n",
      "   Hybrid noise: Experimental std (where available) + 1.5% fallback\n",
      "   Targets scaled by TARGET_Y_SCALES [150, 150, 3, 20] for ReLU activation\n",
      "   🚀 Training 5 models in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=74.638%, R²=0.360\n",
      "      🤖 Model 2: MRE=80.947%, R²=0.387\n",
      "      🤖 Model 3: MRE=80.615%, R²=0.422\n",
      "      🤖 Model 4: MRE=76.953%, R²=0.364\n",
      "      🤖 Model 5: MRE=73.434%, R²=0.373\n",
      "\n",
      "✅ UIP Ensemble Results for 1:100:\n",
      "   📊 Ensemble MRE: 74.248% (original scale)\n",
      "   📊 Ensemble R²: 0.413 (vs individual mean: 0.381)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (256, 128, 64, 32)\n",
      "   📈 Samples: 27573 (101.0x)\n",
      "\n",
      "   📉 Individual Model Losses:\n",
      "      Model 1: Train Loss=0.014962, Val Loss=0.018852\n",
      "      Model 2: Train Loss=0.014731, Val Loss=0.018888\n",
      "      Model 3: Train Loss=0.014943, Val Loss=0.018634\n",
      "      Model 4: Train Loss=0.014950, Val Loss=0.018929\n",
      "      Model 5: Train Loss=0.014785, Val Loss=0.018343\n",
      "   📉 Ensemble Average Losses:\n",
      "      Train Loss: 0.014874 ± 0.000097\n",
      "      Val Loss: 0.018729 ± 0.000218\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# RUN UIP EXPERIMENTS (Simplified!)\n",
    "# ================================\n",
    "# Run UIP experiments for tensile properties\n",
    "print(\"🚀 Starting UIP experiments for tensile properties...\")\n",
    "uip_tensile_results = run_uip_experiment('tensile', [1, 10, 100])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting UIP experiments for optical properties...\n",
      "\n",
      "🚀 UIP EXPERIMENT: OPTICAL\n",
      "============================================================\n",
      "🎯 Target properties: ['TransVis', 'TransIR', 'TransUV']\n",
      "📊 Raw Data: Train=(273, 23), Test=(69, 23) (with experimental std)\n",
      "\n",
      "🔧 Testing UIP Ratio: 1:1\n",
      "----------------------------------------\n",
      "🏗️ Using simple architecture with 5 ensemble models\n",
      "📈 Augmented data: 546 samples (2.0x)\n",
      "   Hybrid noise: Experimental std (where available) + 15.0% fallback\n",
      "   Targets scaled by TARGET_Y_SCALES [300.0, 100.0, 100.0] for Sigmoid activation\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=12.368%, R²=0.191\n",
      "      🤖 Model 2: MRE=12.084%, R²=0.227\n",
      "      🤖 Model 3: MRE=12.217%, R²=0.186\n",
      "      🤖 Model 4: MRE=11.811%, R²=0.240\n",
      "      🤖 Model 5: MRE=11.860%, R²=0.245\n",
      "\n",
      "✅ UIP Ensemble Results for 1:1:\n",
      "   📊 Ensemble MRE: 11.844% (original scale)\n",
      "   📊 Ensemble R²: 0.255 (vs individual mean: 0.218)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (64, 32)\n",
      "   📈 Samples: 546 (2.0x)\n",
      "\n",
      "🔧 Testing UIP Ratio: 1:10\n",
      "----------------------------------------\n",
      "🏗️ Using medium architecture with 5 ensemble models\n",
      "📈 Augmented data: 3003 samples (11.0x)\n",
      "   Hybrid noise: Experimental std (where available) + 4.7% fallback\n",
      "   Targets scaled by TARGET_Y_SCALES [300.0, 100.0, 100.0] for Sigmoid activation\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=11.548%, R²=0.315\n",
      "      🤖 Model 2: MRE=11.295%, R²=0.327\n",
      "      🤖 Model 3: MRE=11.861%, R²=0.268\n",
      "      🤖 Model 4: MRE=12.229%, R²=0.233\n",
      "      🤖 Model 5: MRE=11.631%, R²=0.295\n",
      "\n",
      "✅ UIP Ensemble Results for 1:10:\n",
      "   📊 Ensemble MRE: 11.481% (original scale)\n",
      "   📊 Ensemble R²: 0.316 (vs individual mean: 0.288)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (128, 64, 32)\n",
      "   📈 Samples: 3003 (11.0x)\n",
      "\n",
      "🔧 Testing UIP Ratio: 1:100\n",
      "----------------------------------------\n",
      "🏗️ Using complex architecture with 5 ensemble models\n",
      "📈 Augmented data: 27573 samples (101.0x)\n",
      "   Hybrid noise: Experimental std (where available) + 1.5% fallback\n",
      "   Targets scaled by TARGET_Y_SCALES [300.0, 100.0, 100.0] for Sigmoid activation\n",
      "   🚀 Training 5 models in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=11.223%, R²=0.353\n",
      "      🤖 Model 2: MRE=11.584%, R²=0.295\n",
      "      🤖 Model 3: MRE=12.126%, R²=0.326\n",
      "      🤖 Model 4: MRE=12.384%, R²=0.203\n",
      "      🤖 Model 5: MRE=12.079%, R²=0.178\n",
      "\n",
      "✅ UIP Ensemble Results for 1:100:\n",
      "   📊 Ensemble MRE: 11.117% (original scale)\n",
      "   📊 Ensemble R²: 0.340 (vs individual mean: 0.271)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (256, 128, 64, 32)\n",
      "   📈 Samples: 27573 (101.0x)\n",
      "\n",
      "🎉 All UIP experiments completed!\n",
      "📊 Results are stored in: uip_tensile_results, uip_optical_results\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run UIP experiments for optical properties  \n",
    "print(\"🚀 Starting UIP experiments for optical properties...\")\n",
    "uip_optical_results = run_uip_experiment('optical', [1, 10, 100])\n",
    "\n",
    "print(\"\\n🎉 All UIP experiments completed!\")\n",
    "print(\"📊 Results are stored in: uip_tensile_results, uip_optical_results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 SMOTE EXPERIMENT: TENSILE\n",
      "============================================================\n",
      "🎯 Target properties: ['TensileStress', 'TensileStrain', 'TensileModulusLog10', 'TensileToughnessMean100n90']\n",
      "📊 Raw Data: Train=(273, 23), Test=(69, 23)\n",
      "\n",
      "🔧 Testing SMOTE Ratio: 1:1\n",
      "----------------------------------------\n",
      "🏗️ Using simple architecture with 5 ensemble models\n",
      "⚠️ smogn not available, using simple oversampling for ratio 1:1\n",
      "📈 Augmented data: 546 samples (2.0x)\n",
      "   SMOTE perturbation: 2.0% (adaptive)\n",
      "   Targets scaled by TARGET_Y_SCALES [150, 150, 3, 20] for ReLU activation\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=79.730%, R²=0.637\n",
      "      🤖 Model 2: MRE=83.759%, R²=0.635\n",
      "      🤖 Model 3: MRE=73.803%, R²=0.633\n",
      "      🤖 Model 4: MRE=84.668%, R²=0.640\n",
      "      🤖 Model 5: MRE=87.146%, R²=0.646\n",
      "\n",
      "✅ SMOTE Ensemble Results for 1:1:\n",
      "   📊 Ensemble MRE: 77.354% (original scale)\n",
      "   📊 Ensemble R²: 0.651 (vs individual mean: 0.638)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (64, 32)\n",
      "   📈 Samples: 546 (2.0x)\n",
      "\n",
      "🔧 Testing SMOTE Ratio: 1:10\n",
      "----------------------------------------\n",
      "🏗️ Using medium architecture with 5 ensemble models\n",
      "⚠️ smogn not available, using simple oversampling for ratio 1:10\n",
      "📈 Augmented data: 3003 samples (11.0x)\n",
      "   SMOTE perturbation: 0.6% (adaptive)\n",
      "   Targets scaled by TARGET_Y_SCALES [150, 150, 3, 20] for ReLU activation\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=89.727%, R²=0.593\n",
      "      🤖 Model 2: MRE=89.224%, R²=0.622\n",
      "      🤖 Model 3: MRE=90.795%, R²=0.546\n",
      "      🤖 Model 4: MRE=92.240%, R²=0.578\n",
      "      🤖 Model 5: MRE=97.377%, R²=0.566\n",
      "\n",
      "✅ SMOTE Ensemble Results for 1:10:\n",
      "   📊 Ensemble MRE: 89.064% (original scale)\n",
      "   📊 Ensemble R²: 0.592 (vs individual mean: 0.581)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (128, 64, 32)\n",
      "   📈 Samples: 3003 (11.0x)\n",
      "\n",
      "🔧 Testing SMOTE Ratio: 1:100\n",
      "----------------------------------------\n",
      "🏗️ Using complex architecture with 5 ensemble models\n",
      "⚠️ smogn not available, using simple oversampling for ratio 1:100\n",
      "📈 Augmented data: 27573 samples (101.0x)\n",
      "   SMOTE perturbation: 0.2% (adaptive)\n",
      "   Targets scaled by TARGET_Y_SCALES [150, 150, 3, 20] for ReLU activation\n",
      "   🚀 Training 5 models in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=86.530%, R²=0.586\n",
      "      🤖 Model 2: MRE=86.495%, R²=0.588\n",
      "      🤖 Model 3: MRE=90.944%, R²=0.566\n",
      "      🤖 Model 4: MRE=91.358%, R²=0.596\n",
      "      🤖 Model 5: MRE=86.990%, R²=0.572\n",
      "\n",
      "✅ SMOTE Ensemble Results for 1:100:\n",
      "   📊 Ensemble MRE: 86.263% (original scale)\n",
      "   📊 Ensemble R²: 0.589 (vs individual mean: 0.582)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (256, 128, 64, 32)\n",
      "   📈 Samples: 27573 (101.0x)\n",
      "\n",
      "🚀 BASELINE EXPERIMENT: TENSILE\n",
      "============================================================\n",
      "🎯 Target properties: ['TensileStress', 'TensileStrain', 'TensileModulusLog10', 'TensileToughnessMean100n90']\n",
      "📊 Data: Train=(273, 23), Test=(69, 23)\n",
      "   Targets scaled by TARGET_Y_SCALES [150, 150, 3, 20] for ReLU activation\n",
      "\n",
      "🔧 Testing BASELINE (Architecture: 1:1)\n",
      "----------------------------------------\n",
      "🏗️ Using simple architecture with 5 ensemble models\n",
      "📈 Data: 273 samples (1.0x - no augmentation)\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=81.980%, R²=0.577\n",
      "      🤖 Model 2: MRE=83.110%, R²=0.601\n",
      "      🤖 Model 3: MRE=79.253%, R²=0.585\n",
      "      🤖 Model 4: MRE=80.772%, R²=0.590\n",
      "      🤖 Model 5: MRE=80.174%, R²=0.599\n",
      "\n",
      "✅ BASELINE Ensemble Results for 1:1:\n",
      "   📊 Ensemble MRE: 78.118% (original scale)\n",
      "   📊 Ensemble R²: 0.621 (vs individual mean: 0.590)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (64, 32)\n",
      "   📈 Samples: 273 (1.0x - no augmentation)\n",
      "\n",
      "🔧 Testing BASELINE (Architecture: 1:10)\n",
      "----------------------------------------\n",
      "🏗️ Using medium architecture with 5 ensemble models\n",
      "📈 Data: 273 samples (1.0x - no augmentation)\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=84.471%, R²=0.462\n",
      "      🤖 Model 2: MRE=85.953%, R²=0.478\n",
      "      🤖 Model 3: MRE=77.031%, R²=0.312\n",
      "      🤖 Model 4: MRE=87.715%, R²=0.205\n",
      "      🤖 Model 5: MRE=72.663%, R²=0.479\n",
      "\n",
      "✅ BASELINE Ensemble Results for 1:10:\n",
      "   📊 Ensemble MRE: 79.740% (original scale)\n",
      "   📊 Ensemble R²: 0.480 (vs individual mean: 0.387)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (128, 64, 32)\n",
      "   📈 Samples: 273 (1.0x - no augmentation)\n",
      "\n",
      "🔧 Testing BASELINE (Architecture: 1:100)\n",
      "----------------------------------------\n",
      "🏗️ Using complex architecture with 5 ensemble models\n",
      "📈 Data: 273 samples (1.0x - no augmentation)\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=81.704%, R²=0.076\n",
      "      🤖 Model 2: MRE=75.998%, R²=0.089\n",
      "      🤖 Model 3: MRE=85.205%, R²=0.075\n",
      "      🤖 Model 4: MRE=80.669%, R²=0.238\n",
      "      🤖 Model 5: MRE=77.707%, R²=0.113\n",
      "\n",
      "✅ BASELINE Ensemble Results for 1:100:\n",
      "   📊 Ensemble MRE: 79.839% (original scale)\n",
      "   📊 Ensemble R²: 0.132 (vs individual mean: 0.118)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (256, 128, 64, 32)\n",
      "   📈 Samples: 273 (1.0x - no augmentation)\n"
     ]
    }
   ],
   "source": [
    "# Run SMOTE experiments (optional)\n",
    "smote_tensile_results = run_smote_experiment('tensile', [1, 10, 100])\n",
    "\n",
    "# Run baseline experiments (optional)\n",
    "baseline_tensile_results = run_baseline_experiment('tensile', [1, 10, 100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 SMOTE EXPERIMENT: OPTICAL\n",
      "============================================================\n",
      "🎯 Target properties: ['TransVis', 'TransIR', 'TransUV']\n",
      "📊 Raw Data: Train=(273, 23), Test=(69, 23)\n",
      "\n",
      "🔧 Testing SMOTE Ratio: 1:1\n",
      "----------------------------------------\n",
      "🏗️ Using simple architecture with 5 ensemble models\n",
      "⚠️ smogn not available, using simple oversampling for ratio 1:1\n",
      "📈 Augmented data: 546 samples (2.0x)\n",
      "   SMOTE perturbation: 2.0% (adaptive)\n",
      "   Targets scaled by TARGET_Y_SCALES [300.0, 100.0, 100.0] for Sigmoid activation\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=12.996%, R²=0.134\n",
      "      🤖 Model 2: MRE=12.346%, R²=0.233\n",
      "      🤖 Model 3: MRE=13.134%, R²=0.137\n",
      "      🤖 Model 4: MRE=12.791%, R²=0.136\n",
      "      🤖 Model 5: MRE=12.884%, R²=0.127\n",
      "\n",
      "✅ SMOTE Ensemble Results for 1:1:\n",
      "   📊 Ensemble MRE: 12.549% (original scale)\n",
      "   📊 Ensemble R²: 0.206 (vs individual mean: 0.153)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (64, 32)\n",
      "   📈 Samples: 546 (2.0x)\n",
      "\n",
      "🔧 Testing SMOTE Ratio: 1:10\n",
      "----------------------------------------\n",
      "🏗️ Using medium architecture with 5 ensemble models\n",
      "⚠️ smogn not available, using simple oversampling for ratio 1:10\n",
      "📈 Augmented data: 3003 samples (11.0x)\n",
      "   SMOTE perturbation: 0.6% (adaptive)\n",
      "   Targets scaled by TARGET_Y_SCALES [300.0, 100.0, 100.0] for Sigmoid activation\n",
      "   🚀 Training 5 models in parallel...\n",
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=12.407%, R²=0.226\n",
      "      🤖 Model 2: MRE=12.285%, R²=0.211\n",
      "      🤖 Model 3: MRE=13.467%, R²=0.063\n",
      "      🤖 Model 4: MRE=12.510%, R²=0.172\n",
      "      🤖 Model 5: MRE=12.204%, R²=0.250\n",
      "\n",
      "✅ SMOTE Ensemble Results for 1:10:\n",
      "   📊 Ensemble MRE: 12.277% (original scale)\n",
      "   📊 Ensemble R²: 0.210 (vs individual mean: 0.185)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (128, 64, 32)\n",
      "   📈 Samples: 3003 (11.0x)\n",
      "\n",
      "🔧 Testing SMOTE Ratio: 1:100\n",
      "----------------------------------------\n",
      "🏗️ Using complex architecture with 5 ensemble models\n",
      "⚠️ smogn not available, using simple oversampling for ratio 1:100\n",
      "📈 Augmented data: 27573 samples (101.0x)\n",
      "   SMOTE perturbation: 0.2% (adaptive)\n",
      "   Targets scaled by TARGET_Y_SCALES [300.0, 100.0, 100.0] for Sigmoid activation\n",
      "   🚀 Training 5 models in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "<string>:63: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✅ Successfully trained 5/5 models\n",
      "      🤖 Model 1: MRE=12.299%, R²=0.182\n",
      "      🤖 Model 2: MRE=12.362%, R²=0.179\n",
      "      🤖 Model 3: MRE=12.309%, R²=0.191\n",
      "      🤖 Model 4: MRE=12.350%, R²=0.167\n",
      "      🤖 Model 5: MRE=12.034%, R²=0.194\n",
      "\n",
      "✅ SMOTE Ensemble Results for 1:100:\n",
      "   📊 Ensemble MRE: 12.184% (original scale)\n",
      "   📊 Ensemble R²: 0.194 (vs individual mean: 0.182)\n",
      "   📊 Models trained: 5/5\n",
      "   📊 Architecture: (256, 128, 64, 32)\n",
      "   📈 Samples: 27573 (101.0x)\n"
     ]
    }
   ],
   "source": [
    "smote_tensile_results = run_smote_experiment('optical', [1, 10, 100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
